# -*- coding: utf-8 -*-
"""Prompt Engineering Validator â€“ Tax Compliance Use Case with GPT-3.5 vs GPT-4

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15Snm_A_s6cRhIxk52n28v4Mwn0ufy-7s
"""

!pip install -U langchain-openai openai --quiet
!pip install -U langchain-openai openai

import os
import getpass
from langchain_openai import ChatOpenAI
from langchain.schema import SystemMessage, HumanMessage

# ğŸ” Enter your OpenAI API key securely
os.environ["OPENAI_API_KEY"] = getpass.getpass("ğŸ” Enter your OpenAI API Key: ")

# ğŸ¯ Business Prompt (VAT compliance simulation)
user_prompt = """
You are an Italian tax expert. Briefly list the main VAT obligations for an SRL (limited liability company) under the standard tax regime in 2024. Reply with 5 concise bullet points.
"""

# ğŸ“Œ Enhanced keyword list for evaluation
KEYWORDS = [
    "VAT registration", "VAT return", "VAT invoice",
    "VAT payment", "record keeping", "10 years",
    "deductions", "refund", "Italian Revenue Agency"
]

# âš™ï¸ Generate model output with LangChain wrapper
def generate_response(model_name="gpt-4"):
    llm = ChatOpenAI(model_name=model_name, temperature=0.5)
    messages = [
        SystemMessage(content="You are a senior assistant specialized in Italian tax compliance."),
        HumanMessage(content=user_prompt)
    ]
    response = llm.invoke(messages)
    return response.content

# ğŸ“¤ Evaluate model output relevance
def evaluate_output(output: str, keywords: list):
    score = sum(1 for kw in keywords if kw.lower() in output.lower())
    relevance = "âœ… Sufficient" if score >= 4 else "âš ï¸ Borderline" if score == 3 else "âŒ Low"
    return {
        "output": output,
        "word_count": len(output.split()),
        "keyword_match": score,
        "relevance": relevance
    }

# â–¶ï¸ GPT-3.5 Evaluation
print("\nğŸ”¹ GPT-3.5 Output:\n")
output_35 = generate_response("gpt-3.5-turbo")
eval_35 = evaluate_output(output_35, KEYWORDS)
print(output_35)

print("\nğŸ” GPT-3.5 Evaluation:")
print(f"- Word count: {eval_35['word_count']}")
print(f"- Keyword match: {eval_35['keyword_match']}/9")
print(f"- Relevance: {eval_35['relevance']}")

# â–¶ï¸ GPT-4 Evaluation
print("\nğŸ”· GPT-4 Output:\n")
try:
    output_4 = generate_response("gpt-4")
    eval_4 = evaluate_output(output_4, KEYWORDS)
    print(output_4)

    print("\nğŸ” GPT-4 Evaluation:")
    print(f"- Word count: {eval_4['word_count']}")
    print(f"- Keyword match: {eval_4['keyword_match']}/9")
    print(f"- Relevance: {eval_4['relevance']}")
except Exception as e:
    print("âŒ GPT-4 call failed:", e)