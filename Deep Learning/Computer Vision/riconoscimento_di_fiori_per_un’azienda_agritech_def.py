# -*- coding: utf-8 -*-
"""Riconoscimento di fiori per un’azienda AgriTech def

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1u9UWKWNigzyzhiFdzDWfIBLwNl80yuT4
"""

import requests
import tarfile
import os
from collections import defaultdict
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.utils.data as data_utils
import copy
from statistics import mean
from dataclasses import dataclass, field
import random
import pandas as pd
import seaborn as sns
import numpy as np
import matplotlib as mpl
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, KFold
from sklearn.metrics import confusion_matrix, classification_report
from io import BytesIO
from torchvision import datasets, transforms
from torch.utils.data import DataLoader, ConcatDataset, Subset
from PIL import Image, UnidentifiedImageError
import torchvision.models as models
import torch.optim as optim
import timm
import cv2
from collections import Counter

# Acquire the URL of the tar.gz file
url = "https://proai-datasets.s3.eu-west-3.amazonaws.com/progetto-finale-flowes.tar.gz"

# Download the file
response = requests.get(url)

# Save the downloaded file
with open("progetto-finale-flowes.tar.gz", "wb") as file:
    file.write(response.content)

# Extract the file and count the extracted files
extracted_files_count = 0
total_files_in_archive = 0

try:
    with tarfile.open("progetto-finale-flowes.tar.gz", "r:gz") as tar:
        # Get the total number of files in the archive
        total_files_in_archive = len(tar.getnames())

        # Extract all files
        tar.extractall()
        extracted_files_count = len(tar.getnames())

    # Check the number of files extracted in the directory
    extracted_directory = os.getcwd()
    extracted_files = os.listdir(extracted_directory)

    # Verify if the number of extracted files matches the expected number
    if extracted_files_count == total_files_in_archive:
        print(f"Success! All {total_files_in_archive} files were extracted correctly.")
    else:
        print(f"Warning! Extracted {extracted_files_count} files, but expected {total_files_in_archive} files.")

except Exception as e:
    print(f"An error occurred during extraction: {e}")

# Dataset directory path
dataset_dir = "/content/progetto-finale-flowes"

# Define a function to detect, track, and remove invalid image files
def remove_corrupt_images(dataset_dir):
    invalid_files = []
    for root, _, files in os.walk(dataset_dir):
        for file in files:
            file_path = os.path.join(root, file)
            try:
                with Image.open(file_path) as img:
                    img.verify()  # Verify file integrity
            except (IOError, Image.UnidentifiedImageError):
                invalid_files.append(file_path)
                os.remove(file_path)

    # Print the removed invalid files
    if invalid_files:
        print("Invalid files found and removed:")
        for invalid_file in invalid_files:
            print(f" - {invalid_file}")
    else:
        print("No invalid files found.")

# Function to print class diversity
def print_class_diversity(dataset_dir):
    for split in ['train', 'valid', 'test']:
        split_dir = os.path.join(dataset_dir, split)
        dataset = datasets.ImageFolder(split_dir)
        class_counts = {cls: 0 for cls in dataset.classes}

        for _, label in dataset:
            class_counts[dataset.classes[label]] += 1

        print(f'Class diversity in {split} set:')
        for cls, count in class_counts.items():
            print(f' - {cls}: {count}')

# Run the cleaning function across all dataset folders
remove_corrupt_images(dataset_dir)

# Print class diversity for each set
print_class_diversity(dataset_dir)

# Function to check image brightness
def check_image_brightness(image_path):
    img = cv2.imread(image_path)
    if img is None:  # Check if image was successfully loaded
        print(f"Unable to load image: {image_path}")
        return None

    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    mean_brightness = np.mean(gray)
    return mean_brightness

# Function to analyze images and extract characteristics
def analyze_images_in_sets(dataset_dir):
    characteristics = {
        'train': {
            'total': 0,
            'width': [],
            'height': [],
            'format': set(),
            'channels': set(),
            'pixel_count': [],
            'low_brightness_count': 0,
            'low_resolution_count': 0
        },
        'valid': {
            'total': 0,
            'width': [],
            'height': [],
            'format': set(),
            'channels': set(),
            'pixel_count': [],
            'low_brightness_count': 0,
            'low_resolution_count': 0
        },
        'test': {
            'total': 0,
            'width': [],
            'height': [],
            'format': set(),
            'channels': set(),
            'pixel_count': [],
            'low_brightness_count': 0,
            'low_resolution_count': 0
        }
    }

    for set_name in ['train', 'valid', 'test']:
        set_dir = os.path.join(dataset_dir, set_name)
        if not os.path.exists(set_dir):
            print(f"Warning: Directory {set_name} does not exist and will be skipped.")
            continue

        for class_name in os.listdir(set_dir):
            class_path = os.path.join(set_dir, class_name)
            if os.path.isdir(class_path):
                for file_name in os.listdir(class_path):
                    if file_name.endswith(('.png', '.jpg', '.jpeg')):  # Filter image formats
                        img_path = os.path.join(class_path, file_name)
                        try:
                            with Image.open(img_path) as img:
                                width, height = img.size
                                channels = len(img.getbands())  # Get number of channels
                                pixel_count = width * height   # Calculate total pixels

                                # Update statistics
                                characteristics[set_name]['total'] += 1
                                characteristics[set_name]['width'].append(width)
                                characteristics[set_name]['height'].append(height)
                                characteristics[set_name]['format'].add(file_name.split('.')[-1].lower())
                                characteristics[set_name]['channels'].add(channels)
                                characteristics[set_name]['pixel_count'].append(pixel_count)

                                # Check brightness
                                brightness = check_image_brightness(img_path)
                                if brightness is not None and brightness < 50:  # Brightness threshold
                                    characteristics[set_name]['low_brightness_count'] += 1

                                # Check resolution
                                if width < 128 or height < 128:  # Resolution threshold
                                    characteristics[set_name]['low_resolution_count'] += 1

                        except UnidentifiedImageError:
                            pass

    return characteristics

# Execute the function and get image statistics
image_characteristics = analyze_images_in_sets(dataset_dir)

# Print characteristics per set
for set_name, stats in image_characteristics.items():
    total_images = stats['total']
    widths = stats['width']
    heights = stats['height']
    formats = stats['format']
    channels = stats['channels']
    pixel_counts = stats['pixel_count']
    low_brightness_count = stats['low_brightness_count']
    low_resolution_count = stats['low_resolution_count']

    print(f"\nCharacteristics for {set_name} set:")
    print(f"  Total number of images: {total_images}")

    if widths and heights:
        avg_width = sum(widths) / len(widths)
        avg_height = sum(heights) / len(heights)
        avg_pixel_count = sum(pixel_counts) / len(pixel_counts)
        print(f"  Average image size: {avg_width:.2f} x {avg_height:.2f}")
        print(f"  Average pixel count per image: {avg_pixel_count:.2f}")

    print(f"  File formats present: {', '.join(formats)}")
    print(f"  Number of channels: {', '.join(map(str, channels))}")  # Convert to string for printing
    print(f"  Low-brightness images: {low_brightness_count}")
    print(f"  Low-resolution images: {low_resolution_count}")

# Compute and print class diversity for each set individually
def print_class_diversity(dataset_dir):
    for set_name in ['train', 'valid', 'test']:
        set_dir = os.path.join(dataset_dir, set_name)
        if os.path.exists(set_dir):
            class_counts = Counter()  # Initialize counter per set
            for class_name in os.listdir(set_dir):
                class_path = os.path.join(set_dir, class_name)
                if os.path.isdir(class_path):
                    class_counts[class_name] += len(os.listdir(class_path))

            print(f"\nClass diversity in {set_name} set:")
            for class_name, count in class_counts.items():
                print(f"  Class: {class_name}, Count: {count}")

"""" Dataset Quality Overview & Recommendations
The dataset appears well-structured and of generally high quality, featuring uniformly sized images with a relatively high resolution (512x512 pixels). However, there is room for improvement in both class balance and image quality consistency.

Class Imbalance:
The dataset shows a significant prevalence of the "dandelion" class, which may bias the model during training. To mitigate this, data augmentation techniques should be applied to underrepresented classes in order to enhance class diversity and improve generalization.

Image Brightness Variability:
A number of images exhibit low brightness — specifically, 51 in the training set, 25 in the validation set, and 10 in the test set. This variation can affect model performance and should be addressed by applying normalization and augmentation techniques such as random brightness and contrast adjustments.

Resolution Consistency:
While most images are of adequate resolution, some fall below ideal thresholds. These cases can be handled through resizing and augmentation to maintain robustness across input dimensions.

Suggested Improvements:

Normalize image brightness and scale pixel values.

Apply real-time data augmentation (e.g., random rotation, zoom, brightness shift, flipping).

Monitor model performance with stratified evaluation to ensure class-wise reliability.

By applying these optimizations, the model will be better equipped to handle real-world variability and avoid overfitting to dominant visual patterns or lighting conditions."""

# Define device (use GPU if available)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Main dataset path
data_dir = '/content/progetto-finale-flowes'

# Basic transform for Dandelion class (no augmentation), with ImageNet normalization
base_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))
])

# Data augmentation transform for Daisy class
augmentation_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.RandomRotation(degrees=30),
    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.1),
    transforms.ToTensor(),
    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))
])

# Load full training dataset
train_dataset = datasets.ImageFolder(root=os.path.join(data_dir, 'train'))

# Separate indices for Daisy and Dandelion classes
daisy_indices = [i for i, (_, label) in enumerate(train_dataset) if label == train_dataset.class_to_idx['daisy']]
dandelion_indices = [i for i, (_, label) in enumerate(train_dataset) if label == train_dataset.class_to_idx['dandelion']]

# Create Subset for Daisy with data augmentation
daisy_dataset = Subset(train_dataset, daisy_indices)
daisy_dataset.dataset.transform = augmentation_transform

# Create Subset for Dandelion without augmentation
dandelion_dataset = Subset(train_dataset, dandelion_indices)
dandelion_dataset.dataset.transform = base_transform

# Combine datasets to create a balanced training set
balanced_train_dataset = ConcatDataset([daisy_dataset, dandelion_dataset])

# Create training DataLoader
train_loader = DataLoader(balanced_train_dataset, batch_size=32, shuffle=True)

# Define validation and test set paths
val_data_dir = os.path.join(data_dir, 'valid')
test_data_dir = os.path.join(data_dir, 'test')

# Common transform for validation and test sets
common_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.RandomRotation(degrees=30),
    transforms.ToTensor(),
    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))
])

# Load validation and test datasets
val_dataset = datasets.ImageFolder(root=val_data_dir, transform=common_transform)
test_dataset = datasets.ImageFolder(root=test_data_dir, transform=common_transform)

# Create DataLoaders for validation and test
val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)
test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)

# Utility function to count samples per class
def count_classes(loader):
    class_counts = {0: 0, 1: 0}  # Assuming 0 = daisy, 1 = dandelion
    for _, labels in loader:
        for label in labels:
            class_counts[label.item()] += 1
    return class_counts

# Compute class weights based on sample distribution
num_daisy = len(daisy_indices)
num_dandelion = len(dandelion_indices)
total_samples = num_daisy + num_dandelion

weight_daisy = total_samples / (2 * num_daisy)
weight_dandelion = total_samples / (2 * num_dandelion)

# Define class weights as a tensor for loss function, and move to GPU if available
class_weights = torch.tensor([weight_daisy, weight_dandelion], dtype=torch.float32).to(device)

# Define loss function with class weights
criterion = nn.CrossEntropyLoss(weight=class_weights)

# Print dataset stats
print(f'Balanced training dataset size: {len(balanced_train_dataset)}')
print(f'Class weights — Daisy: {weight_daisy:.2f}, Dandelion: {weight_dandelion:.2f}')

# Count elements per class in each set
train_class_counts = count_classes(train_loader)
val_class_counts = count_classes(val_loader)
test_class_counts = count_classes(test_loader)

print(f'Training set — Daisy: {train_class_counts[0]}, Dandelion: {train_class_counts[1]}')
print(f'Validation set — Daisy: {val_class_counts[0]}, Dandelion: {val_class_counts[1]}')
print(f'Test set — Daisy: {test_class_counts[0]}, Dandelion: {test_class_counts[1]}')

# Load a pre-trained EfficientNet model
model = timm.create_model('efficientnet_b0', pretrained=True)

# Adapt the final classifier layer to match the number of classes
num_classes = len(train_dataset.classes)
model.classifier = nn.Linear(model.classifier.in_features, num_classes)  # Modify final layer for fine-tuning
model = model.to(device)  # Move model to the selected device (GPU or CPU)

# Define the optimizer
optimizer = optim.Adam(model.parameters(), lr=0.001)

# Set up early stopping parameters
best_val_loss = float('inf')
patience = 5
counter = 0

# Initialize lists to track loss and accuracy during training
train_losses = []
train_accuracies = []
val_losses = []
val_accuracies = []

# Start training loop
num_epochs = 50
for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0
    correct = 0
    total = 0

    for inputs, labels in train_loader:
        inputs, labels = inputs.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

    avg_loss = running_loss / len(train_loader)
    train_losses.append(avg_loss)
    train_accuracy = 100 * correct / total
    train_accuracies.append(train_accuracy)

    # Validation phase
    model.eval()
    val_loss = 0.0
    correct = 0
    total = 0

    with torch.no_grad():
        for inputs, labels in val_loader:
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            val_loss += loss.item()
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

    val_loss /= len(val_loader)
    val_losses.append(val_loss)
    val_accuracy = 100 * correct / total
    val_accuracies.append(val_accuracy)

    # Print training and validation metrics
    print(f"Epoch [{epoch + 1}/{num_epochs}] | "
          f"Train Loss: {avg_loss:.4f} | Train Accuracy: {train_accuracy:.2f}% | "
          f"Val Loss: {val_loss:.4f} | Val Accuracy: {val_accuracy:.2f}%")

    # Save best model based on validation loss
    if val_loss < best_val_loss:
        best_val_loss = val_loss
        torch.save(model.state_dict(), 'best_model.pth')
        print(f"Best model saved with validation loss: {val_loss:.4f}")
        counter = 0
    else:
        counter += 1
        if counter >= patience:
            print("Early stopping triggered")
            break

# Plot training and validation loss and accuracy
epochs = range(1, len(train_losses) + 1)

plt.figure(figsize=(12, 5))

# Plot loss curves
plt.subplot(1, 2, 1)
plt.plot(epochs, train_losses, label='Train Loss')
plt.plot(epochs, val_losses, label='Validation Loss')
plt.title('Training and Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

# Plot accuracy curves
plt.subplot(1, 2, 2)
plt.plot(epochs, train_accuracies, label='Train Accuracy')
plt.plot(epochs, val_accuracies, label='Validation Accuracy')
plt.title('Training and Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy (%)')
plt.legend()

plt.tight_layout()
plt.show()

# Final evaluation on the test set
model.load_state_dict(torch.load('best_model.pth'))  # Load the best model saved during training
model.eval()

y_true = []
y_pred = []

# Run inference on test data
with torch.no_grad():
    for inputs, labels in test_loader:
        inputs, labels = inputs.to(device), labels.to(device)
        outputs = model(inputs)
        _, predicted = torch.max(outputs.data, 1)
        y_true.extend(labels.cpu().numpy())
        y_pred.extend(predicted.cpu().numpy())

# Print classification metrics (precision, recall, f1-score)
print(classification_report(y_true, y_pred, target_names=test_dataset.classes))

# Generate confusion matrix
conf_matrix = confusion_matrix(y_true, y_pred)

# Visualize confusion matrix as a heatmap
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',
            xticklabels=test_dataset.classes, yticklabels=test_dataset.classes)
plt.ylabel('True Label')
plt.xlabel('Predicted Label')
plt.title('Confusion Matrix')
plt.show()

# Display confusion matrix as a DataFrame
print("Confusion Matrix:")
df_conf_matrix = pd.DataFrame(conf_matrix, index=test_dataset.classes, columns=test_dataset.classes)
print(df_conf_matrix)

"""# *CONCLUSIONS*

Image Classification Model — Daisy vs. Dandelion
 Project Overview
This project focuses on developing a deep learning model capable of classifying images of flowers into two categories: "daisy" and "dandelion". The objective is to build an automated image recognition system that can support environmental monitoring and ecological analysis applications.

 Dataset
The dataset consists of flower images labeled as either daisy or dandelion, provided via the project's data repository. The images underwent a preprocessing phase and an exploratory data analysis, which revealed a class imbalance skewed in favor of the dandelion class.

 Image Preprocessing
All images were resized to 224x224 pixels to ensure consistent input dimensions for the model.

Normalization was applied using ImageNet mean and standard deviation, to improve training convergence.

The dataset was split into training, validation, and test sets, with validation used to monitor accuracy during training and the test set reserved for final performance evaluation.

To mitigate the imbalance detected during EDA, we applied:

Data augmentation specifically for the daisy class.

Class-weight adjustment in the loss function to reduce training bias.

 Data Augmentation
To address class imbalance, we applied data augmentation only to the minority class (daisy), including:

Random rotations

Random color jittering (brightness, contrast, saturation, hue)

These transformations increase the variability of the daisy class and help the model generalize better to new conditions.

 Model Architecture
We selected EfficientNet B0, a pretrained deep learning model known for its high accuracy and computational efficiency.
The final classification layer was modified to output two classes matching the dataset's structure.

 Loss Function and Optimizer
The CrossEntropyLoss was used, enhanced with class weights to counteract the imbalance between daisy and dandelion samples.

The Adam optimizer was chosen for its adaptive learning rate and proven performance on image classification tasks.

Training was run for up to 50 epochs, with loss and accuracy tracked on both the training and validation sets.

 Early Stopping
To avoid overfitting, early stopping was implemented. The model was saved only when the validation loss improved, ensuring that the best-performing version was retained.

 Evaluation
For final evaluation, we used:

Classification Report (Precision, Recall, F1-score)

Confusion Matrix

Results:

Overall Accuracy: 96%

Only 6 misclassifications, all cases where the model incorrectly predicted dandelion instead of daisy

High precision and recall for both classes, demonstrating strong performance

 Strengths
High Accuracy: The model performs very well in classification.

Environmental Robustness: Data augmentation helps the model handle real-world variations like lighting and orientation.

Efficient Training: EfficientNet allows faster training with fewer resources.

Challenges
Class Imbalance: Despite augmentation, balancing classes remains a challenge.

Generalization: Model performance may degrade if test images are not representative of real-world conditions.

Environmental Variability: Factors like lighting and background can still affect predictions.

 Conclusions
The developed classification model demonstrates solid and reliable performance and can be deployed in real-world scenarios, such as:

Ecosystem monitoring

Automated flower identification in the wild

However, continuous improvement is necessary through expanded data collection and advanced tuning techniques to ensure consistent and trustworthy results.

 Recommendations
Expand the dataset: Collect more images, especially for underrepresented classes.

Field validation: Test the model in real-life settings.

Experiment with other architectures: Compare performance across different CNN models.

Apply regularization or fine-tuning: Further optimize the model in future experiments or dataset expansions."""
"""